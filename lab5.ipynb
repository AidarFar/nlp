{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1uMO0FNnv2yuSgaa_B9foEJY8P1bQZInZ","authorship_tag":"ABX9TyNw6x6NEUs53JFVKdd9+Ct4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,TensorDataset, random_split\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import seaborn as sns\n","import random\n","import torchvision\n","import zipfile\n","from tqdm import tqdm\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n"],"metadata":{"id":"a7-QAyJz5J3V","executionInfo":{"status":"ok","timestamp":1701932202340,"user_tz":-180,"elapsed":16614,"user":{"displayName":"Nudel","userId":"11250601100287929999"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"nAHi-0Q83uz-","executionInfo":{"status":"ok","timestamp":1701932202340,"user_tz":-180,"elapsed":3,"user":{"displayName":"Nudel","userId":"11250601100287929999"}}},"outputs":[],"source":["def train(model, optimizer, train_loader, device, criterion, n_epochs):\n","    # Переводим модель в режим обучения\n","    model.train()\n","    model.to(device)\n","    # Список для хранения значений функции потерь\n","    losses_per_epoch = []\n","\n","    for epoch in range(1, n_epochs + 1):\n","        list_process = []  # Очищаем список для каждой эпохи\n","\n","        for batch_idx, (input_ids, attention_mask, labels) in enumerate(train_loader):\n","            # Переносим данные и цели на указанное устройство (например, GPU)\n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","            # Обнуляем градиенты оптимизатора\n","            optimizer.zero_grad()\n","\n","            # Подсчет прогнозов модели\n","            output = model(input_ids, attention_mask=attention_mask)\n","\n","            # Вычисление функции потерь (лосса) между прогнозами и истинными значениями\n","            loss = criterion(output.logits, labels)\n","\n","            # Расчет градиентов и выполнение одного шага оптимизатора\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Добавляем значение лосса в список процесса обучения\n","            list_process.append(loss.item())\n","\n","            if batch_idx % 100 == 0:\n","                # Выводим информацию о процессе обучения каждые 100 батчей\n","                print(f'Train Epoch: {epoch} [{batch_idx * len(input_ids)}/{len(train_loader.dataset)} '\n","                      f'({100. * batch_idx / len(train_loader):.2f}%)]\\tLoss: {loss.item():.6f}')\n","\n","        # Выводим общую информацию о лоссе на данной эпохе\n","        epoch_loss = sum(list_process) / len(list_process)\n","        print(f'Train Epoch: {epoch}\\tAverage Loss: {epoch_loss:.6f}')\n","        losses_per_epoch.append(epoch_loss)\n","\n","    return losses_per_epoch\n"]},{"cell_type":"code","source":["def train_and_evaluate_model(model, optimizer, train_loader, test_loader, device, criterion, n_epochs):\n","    # Обучение модели\n","    losses_per_epoch = train(model, optimizer, train_loader, device, criterion, n_epochs)\n","\n","    # Вывод графика функции потерь по эпохам\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(range(1, n_epochs + 1), losses_per_epoch)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Training Loss')\n","    plt.show()\n","\n","    # Оценка модели на тестовом наборе\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    predicted_labels = []\n","    true_labels = []\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            predicted_labels.extend(predicted.cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    # Вывод матрицы ошибок\n","    cm = confusion_matrix(true_labels, predicted_labels)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","    # Вывод точности на тестовом наборе\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    print(f'Accuracy on the test set: {accuracy * 100:.2f}%')"],"metadata":{"id":"ZAJbdqzc4u_W","executionInfo":{"status":"ok","timestamp":1701932202341,"user_tz":-180,"elapsed":3,"user":{"displayName":"Nudel","userId":"11250601100287929999"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/MyDrive/datasets/balanced_df.csv\")\n","data['Review Text'] = data['Review Text'].astype(str)"],"metadata":{"id":"q0kPqOki6tj9","executionInfo":{"status":"ok","timestamp":1701932202341,"user_tz":-180,"elapsed":3,"user":{"displayName":"Nudel","userId":"11250601100287929999"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data['Rating'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOri0RKXEES9","executionInfo":{"status":"ok","timestamp":1701932205537,"user_tz":-180,"elapsed":838,"user":{"displayName":"Nudel","userId":"11250601100287929999"}},"outputId":"19eda9db-6f95-4b72-dbb9-96fa9254093e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1902\n","2    1902\n","3    1902\n","4    1902\n","5    1902\n","Name: Rating, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# Initializing the BERT tokenizer with max_length\n","max_length = 512  # Set your desired maximum sequence length\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', max_length=max_length)\n","\n","# Applying the tokenizer to the 'Review Text' column\n","def preprocess_data(reviews, ratings):\n","    tokenized_inputs = reviews.apply(lambda x: tokenizer(x, padding='max_length', truncation=True, return_tensors='pt'))\n","    input_ids = torch.cat([tensor['input_ids'] for tensor in tokenized_inputs], dim=0)\n","    attention_mask = torch.cat([tensor['attention_mask'] for tensor in tokenized_inputs], dim=0)\n","    labels = torch.tensor(ratings.tolist())\n","    return TensorDataset(input_ids, attention_mask, labels)\n","\n","# Creating DataLoader for training set\n","train_dataset = preprocess_data(train_data['Review Text'], train_data['Rating'])\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","# Creating DataLoader for test set\n","test_dataset = preprocess_data(test_data['Review Text'], test_data['Rating'])\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"PX1aTuwe7V8u","executionInfo":{"status":"ok","timestamp":1701932266163,"user_tz":-180,"elapsed":50271,"user":{"displayName":"Nudel","userId":"11250601100287929999"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n","# Замените оптимизатор, функцию потерь и количество эпох на свои\n","optimizer = AdamW(bert_model.parameters(), lr=1e-5)\n","criterion = nn.CrossEntropyLoss()\n","n_epochs = 3\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","train_and_evaluate_model(bert_model, optimizer, train_loader, test_loader, device, criterion, n_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcqxtHO74v0E","outputId":"46117618-2ce2-4a9b-ffbb-a5ee6b6e832e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"S5OuJ2Lk7t8e","executionInfo":{"status":"aborted","timestamp":1701931976157,"user_tz":-180,"elapsed":2,"user":{"displayName":"Nudel","userId":"11250601100287929999"}}},"execution_count":null,"outputs":[]}]}